{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "w6K7xa23Elo4",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "nqoHp30x9hH9",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "zVGeBEFhpsJ2",
        "Z-hykwinpx6N",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azorrockss/Assignment-1/blob/main/Flipkart_Customer_Service_Satisfaction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Flipkart Customer Service Satisfaction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### Team Member 1 -  Azor Solomon L S"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PMgBb8_SOcLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objective:\n",
        "The aim of this project is to develop a classification model to predict customer satisfaction scores for Flipkart. This predictive model will help the company identify areas for improvement in customer experience and optimize their marketing and service strategies, ultimately enhancing customer retention and satisfaction.\n",
        "\n",
        "Dataset Overview:\n",
        "The dataset comprises 20 columns, with several features showing a strong correlation to customer behavior. Key customer-related variables includes Order_ID, Order_date_time, Customer_City, Item_Price, Channel_Name, and Customer_Remarks. Additionally, key operational variables include Issue_Responded_at, Issue_Responded, Survey_Response_Date, Product_Category, Agent_Name, Supervisor, Manager, Agent_Shift, and Sub_Category. The target variable is the CSAT Score, which ranges from 1 to 5, indicating customer satisfaction—higher scores reflect greater satisfaction.\n",
        "\n",
        "Data Manipulation:\n",
        "The date variables were converted from object type to datetime format for improved processing. The Connected_Handling_Time column was removed due to having 99% of its values as null. Additionally, any rows with null values in the Order_ID column were eliminated. To address missing data, null values in categorical columns, including Customer_City, Customer_Remarks, and Product_Category, as well as in numeric columns like Item_Price, Issue_Reported_at, and Issue_Responded, were filled appropriately.\n",
        "\n",
        "Exploratory Data Analysis (EDA):\n",
        "The EDA phase involved a comprehensive exploration of the dataset to uncover trends, patterns and relationships that could inform the model-building process\n",
        "\n",
        "Data Cleaning and Preparation:\n",
        "Handling Missing Data: The dataset was evaluated for missing values, and suitable imputation strategies were implemented to maintain data integrity.\n",
        "\n",
        "Feature Engineering:\n",
        "Data Types: The year, month, day, hour, and minute were extracted from the Order_Date_Time column to derive additional valuable insights. Outliers: The Item_Price column was analyzed for outliers using the IQR method, leading to the removal of 23.85% of data points that fell outside acceptable limits. Encoding: One-Hot Encoding was applied to categorical features such as Channel_name and Product_Category.\n",
        "\n",
        "Univariate Analysis:\n",
        "Histograms and box plots were employed to analyze the distribution of continuous variables like Item_price and CSAT Score.\n",
        "\n",
        "Data Splitting:\n",
        "The data was split into training and test sets with an 80-20 ratio. Several classification models were trained, including Logistic Regression, Decision Trees, Random Forest, kNeighbors and Extratrees classifier. Hyperparameter tuning was performed, focusing on F1-Score as the primary evaluation metric to balance precision and recall.\n",
        "\n",
        "Model Evaluation:\n",
        "The models were evaluated using Precision, Recall, F1-Score, and Accuracy. The Extra trees model exhibited the best performance, particularly in terms of precision and accuracy, making it the model of choice. The confusion matrix and ROC-AUC curve further supported the model's effectiveness in distinguishing between satisfied and dissatisfied customers. Feature Importance:\n",
        "\n",
        "The model identified Customer_Remarks, issue_responded, Channel_name and category as the most significant factors influencing customer satisfaction. This suggests that Customer_Remarks, issue_resoponded are crucial for enhancing customer satisfaction.\n",
        "\n",
        "Data Cleaning and Preparation:\n",
        "Handling Missing Data: The dataset was evaluated for missing values, and suitable imputation strategies were implemented to maintain data integrity.\n",
        "\n",
        "Feature Engineering:\n",
        "Data Types: The year, month, day, hour, and minute were extracted from the Order_Date_Time column to derive additional valuable insights. Outliers: The Item_Price column was analyzed for outliers using the IQR method, leading to the removal of 23.85% of data points that fell outside acceptable limits. Encoding: One-Hot Encoding was applied to categorical features such as Channel_name and Product_Category.\n",
        "\n",
        "Univariate Analysis:\n",
        "Histograms and box plots were employed to analyze the distribution of continuous variables like Item_price and CSAT Score.\n",
        "\n",
        "Data Splitting:\n",
        "The data was split into training and test sets with an 80-20 ratio. Several classification models were trained, including Logistic Regression, Decision Trees, Random Forest, kNeighbors and Extratrees classifier. Hyperparameter tuning was performed, focusing on F1-Score as the primary evaluation metric to balance precision and recall.\n",
        "\n",
        "Model Evaluation:\n",
        "The models were evaluated using Precision, Recall, F1-Score, and Accuracy. The Extra trees model exhibited the best performance, particularly in terms of precision and accuracy, making it the model of choice. The confusion matrix and ROC-AUC curve further supported the model's effectiveness in distinguishing between satisfied and dissatisfied customers. Feature Importance:\n",
        "\n",
        "The model identified Customer_Remarks, issue_responded, Channel_name and category as the most significant factors influencing customer satisfaction. This suggests that Customer_Remarks, issue_resoponded are crucial for enhancing customer satisfaction."
      ],
      "metadata": {
        "id": "FWUfh7V7UkIY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zJcWdqwDUkrj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "G9-WijoRUk5f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gFMeFKP4UlE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here.\n",
        "\n"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement: This project predicts Flipkart customer satisfaction using machine learning to uncover key factors that drive service quality and loyalty.\n",
        "\n",
        "Context:\n",
        "In the highly competitive e-commerce industry, customer satisfaction is a critical determinant of brand loyalty and long-term growth. As one of the largest e-commerce platforms, Flipkart handles millions of customer interactions across various support channels such as email, phone, live chat, and social media. Maintaining high levels of customer satisfaction is essential for retaining customers and enhancing their shopping experience. Understanding the factors that influence customer satisfaction and being able to predict CSAT scores based on these factors can significantly improve Flipkart's customer service performance and help in optimizing resources.\n",
        "\n",
        "Objective:\n",
        "The primary objective of this project is to develop a machine learning model that can predict customer satisfaction scores (CSAT) based on historical customer interaction data. By analyzing different features such as customer demographics, interaction types, issue resolution times, support channel performance, and agent efficiency, the model will identify the key drivers of customer satisfaction and provide actionable insights for improving the overall customer service experience. The target variable is the CSAT score, which reflects the satisfaction level of customers after interacting with Flipkart's support team.\n",
        "\n",
        "Key Challenges:\n",
        "Data Imbalance: The dataset may contain an imbalanced distribution of high and low satisfaction scores, which can lead to biased predictions. Addressing this issue with techniques like oversampling, undersampling, or advanced algorithms will be crucial.\n",
        "\n",
        "Feature Engineering: Accurately capturing the drivers of customer satisfaction will require careful feature engineering. This may involve creating new features related to agent performance, interaction duration, issue complexity, and support channel usage to improve model accuracy.\n",
        "\n",
        "Multichannel Integration: Customer interactions occur across different support channels (e.g. inbound, outcall, email). Integrating and normalizing these interactions for model input poses a challenge, especially when data comes in different formats and volumes from each channel.\n",
        "\n",
        "Scalability: Given the high volume of customer interactions, the model needs to be scalable to handle large datasets in real-time scenarios while maintaining prediction accuracy.\n",
        "\n",
        "Model Evaluation: Since the goal is to accurately predict satisfaction levels, precision, recall, and F1-score metrics will be essential in evaluating the model’s performance, with a particular focus on avoiding false negatives (i.e., predicting high satisfaction when the customer is actually dissatisfied).\n",
        "\n",
        "Deliverables:\n",
        "A machine learning model capable of predicting customer satisfaction (CSAT) based on customer interaction data.\n",
        "\n",
        "A detailed report on data preprocessing steps, feature engineering, model selection, evaluation metrics, and key insights derived from the analysis"
      ],
      "metadata": {
        "id": "CfeGh8F9Opjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from scipy.stats import norm\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "df = pd.read_csv('/content/Customer_support_data.csv')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "rows, columns = df.shape\n",
        "\n",
        "print(f\"🔢 Number of Rows: {rows}\")\n",
        "print(f\"📊 Number of Columns: {columns}\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "sns.heatmap(df.isnull(), cbar=False)\n"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 🔍 Set plot style\n",
        "plt.style.use(\"seaborn-v0_8-whitegrid\")\n",
        "\n",
        "# 📊 Plot heatmap of missing values\n",
        "plt.figure(figsize=(14, 6))\n",
        "sns.heatmap(df.isnull(), cbar=False, cmap='Reds', yticklabels=False)\n",
        "plt.title(\"🔍 Heatmap of Missing Values in Dataset\", fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KWW3zTqhaOW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Purpose:\n",
        "\n",
        "Tracks customer support interactions, including issue resolution, agent performance, and customer feedback.\n",
        "\n",
        "Key Columns:\n",
        "\n",
        "Unique ID: Unique identifier for each support case.\n",
        "\n",
        "Channel Name: Communication channel (e.g., Inbound, Outcall, Email).\n",
        "\n",
        "Category/Sub-category: Type of issue (e.g., Returns, Order Related, Product Queries).\n",
        "\n",
        "Customer Remarks: Free-text feedback from customers (e.g., complaints, praises).\n",
        "\n",
        "Order/Issue Dates: Dates for order placement, issue reporting, and resolution.\n",
        "\n",
        "CSAT Score: Customer satisfaction rating (1–5 scale).\n",
        "\n",
        "Agent/Team Details: Agent names, supervisors, managers, and tenure buckets (e.g., \"On Job Training\", \">90 days\").\n",
        "\n",
        "Product/Order Data: Product category, item price, and city of customer.\n",
        "\n",
        "Data Characteristics:\n",
        "\n",
        "Size: 500+ rows (sample provided).\n",
        "\n",
        "Timeframe: Primarily August 2023.\n",
        "\n",
        "Missing Values: Some fields (e.g., Customer Remarks, Item_price) are empty in certain rows.\n",
        "\n",
        "Key Observations:\n",
        "\n",
        "CSAT Scores: Mostly 4–5, with some low scores (1–2) linked to unresolved issues or delays.\n",
        "\n",
        "Common Issues:\n",
        "\n",
        "Returns (e.g., reverse pickup, missing/damaged items).\n",
        "\n",
        "Order delays or cancellations.\n",
        "\n",
        "Product-specific queries.\n",
        "\n",
        "Customer Sentiment:\n",
        "\n",
        "Positive remarks: \"Very good,\" \"Excellent service.\"\n",
        "\n",
        "Negative remarks: \"Pathetic service,\" \"Issue not resolved.\"\n",
        "\n",
        "Agent Performance:\n",
        "\n",
        "Tenure buckets range from \"On Job Training\" to \">90 days.\"\n",
        "\n",
        "Teams are structured hierarchically (Agent → Supervisor → Manager).\n",
        "\n",
        "Potential Use Cases:\n",
        "\n",
        "Customer Experience Analysis: Identify pain points (e.g., frequent return issues).\n",
        "\n",
        "Agent Performance: Correlate tenure/team with CSAT scores.\n",
        "\n",
        "Process Improvement: Address delays or miscommunication flagged in remarks.Answer Here"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns\n"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()\n"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Column Name**           | **Description**                                                                 |\n",
        "| ------------------------- | ------------------------------------------------------------------------------- |\n",
        "| `Unique id`               | A unique identifier for each customer support interaction.                      |\n",
        "| `channel_name`            | Source of contact: e.g., `Inbound`, `Outcall`, `Email`, etc.                    |\n",
        "| `category`                | Broad category of issue: e.g., `Returns`, `Order Related`, `Product Queries`.   |\n",
        "| `Sub-category`            | Specific issue within the category: e.g., `Late Delivery`, `Installation`, etc. |\n",
        "| `Customer Remarks`        | Feedback or notes left by the customer (may contain text or be blank).          |\n",
        "| `Order_id`                | Unique ID for the customer's order (if available).                              |\n",
        "| `order_date_time`         | Date and time when the order was placed.                                        |\n",
        "| `Issue_reported at`       | Date and time when the issue was raised by the customer.                        |\n",
        "| `issue_responded`         | Date and time when the issue was first responded to by an agent.                |\n",
        "| `Survey_response_Date`    | Date when the customer submitted the satisfaction survey.                       |\n",
        "| `Customer_City`           | The city where the customer is located.                                         |\n",
        "| `Product_category`        | Type of product involved in the support issue.                                  |\n",
        "| `Item_price`              | Price of the item related to the support case.                                  |\n",
        "| `connected_handling_time` | Time spent (in minutes) by the agent handling the query.                        |\n",
        "| `Agent_name`              | Name of the agent who handled the case.                                         |\n",
        "| `Supervisor`              | Supervisor under whom the agent reports.                                        |\n",
        "| `Manager`                 | Manager responsible for the support team.                                       |\n",
        "| `Tenure Bucket`           | Agent’s experience range: e.g., `On Job Training`, `0-30`, `>90` days.          |\n",
        "| `Agent Shift`             | The work shift of the agent: `Morning`, `Evening`, etc.                         |\n",
        "| `CSAT Score`              | Customer Satisfaction score (usually 1 to 5).                                   |\n",
        "Answer Here"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XeGvFdJ7cPkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "df.nunique()\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready."
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making a copy of the dataset to avoid modifying the original data\n",
        "df_cleaned = df.copy()"
      ],
      "metadata": {
        "id": "iOmoObACf_TN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing column names\n",
        "df_cleaned.columns = (\n",
        "    df_cleaned.columns.str.lower()\n",
        "    .str.replace(\" \", \"_\")\n",
        "    .str.replace(\"-\", \"_\")\n",
        "    .str.strip()\n",
        ")"
      ],
      "metadata": {
        "id": "H4PopW-4gJ-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a new column for response time (in minutes)\n",
        "if \"issue_reported_at\" in df_cleaned.columns and \"issue_responded\" in df_cleaned.columns:\n",
        "    # Convert columns to datetime objects with the correct format\n",
        "    df_cleaned[\"issue_reported_at\"] = pd.to_datetime(\n",
        "        df_cleaned[\"issue_reported_at\"], format=\"%d/%m/%Y %H:%M\", errors=\"coerce\"\n",
        "    )\n",
        "    df_cleaned[\"issue_responded\"] = pd.to_datetime(\n",
        "        df_cleaned[\"issue_responded\"], format=\"%d/%m/%Y %H:%M\", errors=\"coerce\"\n",
        "    )\n",
        "\n",
        "    # Creating response time column\n",
        "    df_cleaned[\"response_time\"] = (\n",
        "        df_cleaned[\"issue_responded\"] - df_cleaned[\"issue_reported_at\"]\n",
        "    ).dt.total_seconds() / 60  # Convert seconds to minutes\n",
        "print(df_cleaned[[\"issue_reported_at\", \"issue_responded\", \"response_time\"]].head())"
      ],
      "metadata": {
        "id": "CpKK3OAMgUIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing values\n",
        "categorical_cols = [\"customer_city\", \"product_category\", \"customer_remarks\"]\n",
        "for col in categorical_cols:\n",
        "    if col in df_cleaned.columns:\n",
        "        df_cleaned[col] = df_cleaned[col].fillna(\"Unknown\")\n"
      ],
      "metadata": {
        "id": "kar-rLlygk0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling missing values: Filling missing numerical values with median\n",
        "if \"item_price\" in df_cleaned.columns:\n",
        "    df_cleaned[\"item_price\"] = df_cleaned[\"item_price\"].fillna(df_cleaned[\"item_price\"].median())"
      ],
      "metadata": {
        "id": "HSAEdQbJglC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping duplicate records\n",
        "df_cleaned = df_cleaned.drop_duplicates()"
      ],
      "metadata": {
        "id": "GNRTHaqBglMs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for outliers in response_time\n",
        "if \"response_time\" in df_cleaned.columns:\n",
        "    Q1 = df_cleaned[\"response_time\"].quantile(0.25)\n",
        "    Q3 = df_cleaned[\"response_time\"].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    # Filtering out extreme outliers\n",
        "    df_cleaned = df_cleaned[\n",
        "        (df_cleaned[\"response_time\"] >= lower_bound) & (df_cleaned[\"response_time\"] <= upper_bound)\n",
        "    ]"
      ],
      "metadata": {
        "id": "4AHBq7pXglVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtering out extreme outliers\n",
        "df_cleaned = df_cleaned[(df_cleaned[\"response_time\"] >= lower_bound) & (df_cleaned[\"response_time\"] <= upper_bound)]"
      ],
      "metadata": {
        "id": "QK8I9p7hglb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Final dataset info\n",
        "print(\"Final Dataset Info:\")\n",
        "df_cleaned.info()"
      ],
      "metadata": {
        "id": "byeD_fK8hFke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Standardized Column Names**\n",
        "\n",
        "Converted all column names to lowercase.\n",
        "Replaced spaces and special characters (-) with underscores (_).\n",
        "Trimmed any extra spaces.\n",
        "\n",
        "**2.Converted Date Columns to Datetime Format**\n",
        "\n",
        "Transformed order_date_time, issue_reported_at, issue_responded, and survey_response_date to datetime format.\n",
        "Used errors='coerce' to handle incorrect formats.\n",
        "Set dayfirst=True to match the dataset format.\n",
        "\n",
        "**3.Created a New Feature: Response Time**\n",
        "\n",
        "Calculated response time in minutes using:\n",
        "df_cleaned[\"response_time\"] = (df_cleaned[\"issue_responded\"] - df_cleaned[\"issue_reported_at\"]).dt.total_seconds() / 60\n",
        "This helps measure customer support efficiency.\n",
        "\n",
        "**4.Handled Missing Values**\n",
        "\n",
        "Categorical columns (customer_city, product_category, customer_remarks): Filled missing values with \"Unknown\".\n",
        "Numerical column (item_price): Replaced missing values with the median instead of mean to prevent skewness.\n",
        "\n",
        "**5.Dropped Duplicate Records**\n",
        "\n",
        "Ensured dataset integrity by removing duplicate rows.\n",
        "\n",
        "**6.Detected and Handled Outliers**\n",
        "\n",
        "* Used Interquartile Range (IQR) method to detect outliers in response_time.\n",
        "* Filtered out extreme values that might be data entry errors or unusual delaysAnswer Here."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 CSAT Score Distribution\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.countplot(x=df_cleaned['csat_score'],hue=df_cleaned['csat_score'], palette='viridis')\n",
        "plt.title(\"Distribution of CSAT Scores\")\n",
        "plt.xlabel(\"CSAT Score\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is an effective way to visualize the distribution of CSAT (Customer Satisfaction) scores. It provides a clear representation of how frequently each score appears, making it easy to identify trends in customer satisfaction."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*The majority of customers have given a CSAT score of 5, indicating high satisfaction.\n",
        "*A smaller portion of customers have given lower scores (1 to 4), with the lowest counts observed for scores of 2 and 3.\n",
        "*There is a significant gap between the number of customers who rated 5 and those who rated below 4, suggesting that most interactions are positive"
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The high number of 5-star ratings is a positive indicator, as it reflects strong customer satisfaction. This can boost brand loyalty and improve business reputation.\n",
        "* However, the presence of lower ratings (especially score 1) indicates that a segment of customers had a poor experience. Identifying the reasons behind these low ratings could help improve service quality and reduce negative feedback.\n",
        "* Addressing the concerns of dissatisfied customers (scores 1–3) could further enhance the overall customer experience and lead to improved retention rates."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 Top 10 Most Reported Issue Categories\n",
        "top_categories = df_cleaned['category'].value_counts().head(10)\n",
        "top_categories.plot(kind='bar', figsize=(10,5), colormap='coolwarm')\n",
        "plt.title(\"Top 10 Most Reported Issue Categories\")\n",
        "plt.xlabel(\"Issue Category\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is ideal for visualizing the frequency of different issue categories reported by customers. It provides a clear comparison of the most common issues, making it easy to identify trends and prioritize problem areas for business improvements."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* \"Returns\" is the most reported issue category, significantly higher than other categories.\n",
        "* \"Order Related\" issues are the second most common, though still far lower than \"Returns.\"\n",
        "* Other categories like \"Refund Related,\" \"Product Queries,\" and \"Shopzilla Related\" have much lower counts but are still significant.\n",
        "* Issues like \"Offers & Cashback\" and \"Others\" are reported at very low frequencies."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The high number of return-related issues suggests a need to improve product quality, descriptions, or customer expectations to reduce unnecessary returns.\n",
        "* Frequent order-related issues indicate potential challenges with logistics, delivery, or order processing, which need optimization to improve customer experience.\n",
        "* Addressing refund-related complaints efficiently can increase customer satisfaction and trust.\n",
        "* If \"Returns\" and \"Order Related\" issues remain unresolved, it could negatively impact customer retention, leading to lost revenue and increased operational costs.\n"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 Top 10 Customer Cities by Issue Count\n",
        "plt.figure(figsize=(12, 5))\n",
        "# Remove 'Unknown' values and get top 10 cities\n",
        "city_counts = df_cleaned[df_cleaned['customer_city'] != 'Unknown']['customer_city'].value_counts().head(10)\n",
        "city_counts.plot(kind='bar', colormap='viridis')\n",
        "plt.title(\"Top 10 Customer Cities by Issue Count (Without 'Unknown')\")\n",
        "plt.xlabel(\"City\")\n",
        "plt.ylabel(\"Issue Count\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A bar chart is well-suited for visualizing categorical data such as the number of reported issues by city. It allows for a clear comparison of the cities with the highest customer complaints, helping businesses target location-specific improvements."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Hyderabad has the highest number of customer issues, followed by New Delhi and Pune.\n",
        "* Mumbai, Bangalore, and Kolkata also have significant complaint volumes but are lower than the top three cities.\n",
        "* The issue count is relatively lower for cities like Chennai, Lucknow, Ahmedabad, and Jaipur.\n",
        "* The regional disparity in complaints suggests that customer service challenges may be more prominent in certain areas."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Identifying cities with the highest issue counts enables businesses to allocate resources effectively, such as improving logistics, customer support, or product quality in those regions.\n",
        "* If Hyderabad and New Delhi have a disproportionate number of complaints, it might indicate localized service inefficiencies, leading to negative customer sentiment and potential churn.\n",
        "* Addressing city-specific challenges can improve customer satisfaction, reduce issue volume, and enhance brand reputation, positively impacting business growth"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 Response Time Distribution\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df_cleaned['response_time'], bins=30, kde=True, color='blue')\n",
        "plt.title(\"Distribution of Response Time\")\n",
        "plt.xlabel(\"Response Time (minutes)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram with a KDE (Kernel Density Estimate) curve is ideal for visualizing the distribution of response times. It helps identify the most common response times, outliers, and overall trends in customer support efficiency"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The majority of response times are concentrated near zero, indicating that most queries are resolved quickly.\n",
        "* There is a long right tail, suggesting that while most responses are fast, some take significantly longer.\n",
        "* A small number of negative values might indicate incorrect data entries or errors in logging response times."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The fast response times for most queries indicate efficient customer service, which positively impacts customer satisfaction.\n",
        "* However, the long tail of slower responses suggests that some cases take much longer to resolve, which could lead to negative customer experiences.\n",
        "* Addressing delays and reducing variance in response times could improve overall efficiency and customer satisfaction, leading to a more consistent support experience."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 Heatmap of CSAT Scores for Top 10 Agents Across Shifts\n",
        "# Get the top 10 agents by average CSAT score\n",
        "top_agents = df_cleaned.groupby('agent_name')['csat_score'].mean().nlargest(10).index\n",
        "\n",
        "# Filter dataset for these agents\n",
        "df_top_agents = df_cleaned[df_cleaned['agent_name'].isin(top_agents)]\n",
        "\n",
        "# Create a pivot table for CSAT scores by agent and shift\n",
        "csat_pivot = df_top_agents.pivot_table(index='agent_name', columns='agent_shift', values='csat_score', aggfunc='mean')\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(csat_pivot, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "\n",
        "plt.title(\"Average CSAT Scores of Top 10 Agents Across Shifts\")\n",
        "plt.xlabel(\"Agent Shift\")\n",
        "plt.ylabel(\"Agent Name\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A heatmap is ideal for comparing CSAT (Customer Satisfaction) scores across different agents and shifts. The color gradient quickly highlights performance variations, making it easy to identify top-performing agents and potential areas for improvement."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Timothy Bailey (Afternoon shift) has the highest CSAT score (4.96), indicating exceptional customer service performance.\n",
        "* Alan Cruz (Afternoon shift) has the lowest CSAT score (4.89), which, while still high, is lower compared to others.\n",
        "* Agents working Split shifts tend to have higher CSAT scores (4.93-4.94) compared to those in the Morning and Evening shifts (4.90-4.92).\n",
        "*There is no drastic variation, suggesting overall good customer service consistency."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Identifying top-performing agents (e.g., Timothy Bailey) helps recognize best practices and apply them across shifts.\n",
        "* Afternoon shifts might need performance improvement strategies since they show the most variation in scores."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 Issue Reported Volume by Channel\n",
        "plt.figure(figsize=(8,8))\n",
        "df_cleaned['channel_name'].value_counts().plot.pie(autopct='%1.1f%%', colormap='coolwarm')\n",
        "plt.title(\"Issue Volume by Communication Channel\")\n",
        "plt.ylabel(\"\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pie chart is suitable for showing the distribution of issue volumes across different communication channels. It provides a clear, proportional representation of how issues are received."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The majority (79.5%) of issues are handled through inbound communication, meaning customers initiate contact for support.\n",
        "* Outcall interactions account for 17.1%, suggesting that a proactive customer support strategy is in place, likely for follow-ups or issue resolution.\n",
        "* Email is the least used channel (3.4%), indicating that it is not a preferred method for customer issue resolution."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Since inbound calls dominate, optimizing call center efficiency, agent training, and self-service solutions (FAQs, chatbots) can reduce wait times and improve resolution rates.\n",
        "* The low volume of email support (3.4%) could indicate an underutilized or inefficient channel. If email is intended to be a primary support method, then efforts should be made to improve its accessibility and response times."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "numeric_df = df_cleaned.select_dtypes(include=['number'])\n",
        "\n",
        "# Plot heatmap\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A correlation heatmap is ideal for understanding relationships between numerical variables in customer support data. It helps identify positive or negative correlations, guiding business decisions based on data-driven insights."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Item price and connected handling time have a moderate positive correlation (0.44), meaning higher-priced items tend to take longer to resolve.\n",
        "* CSAT score has a weak negative correlation with connected handling time (-0.08) and response time (-0.13), indicating that longer response and handling times slightly lower customer satisfaction.\n",
        "* Item price has almost no correlation with response time (0.02) or CSAT score (-0.07), suggesting that item cost does not significantly impact customer satisfaction directly.\n",
        "* Connected handling time and response time are weakly negatively correlated (-0.08), meaning they don’t strongly impact each other.\n",
        "Higher-priced items taking longer to handle could frustrate premium customers.\n",
        "* Slight negative correlation between response time and CSAT score indicates that reducing delays may improve satisfaction."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "top_agent = df_cleaned['agent_name'].value_counts().nlargest(10)\n",
        "plt.figure(figsize = (10, 6))\n",
        "sns.barplot(x = top_agent.values, y = top_agent.index, palette = 'inferno')\n",
        "plt.title('Top 10 Agent', fontsize = 14)\n",
        "plt.xlabel('Number of Occurrences', fontsize = 12)\n",
        "plt.ylabel('Agent Name', fontsize = 12)\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I had picked bar-chart to identify the top Agent."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart reveals that Agent Wendy Taylor is the most occured Agent where as the Agent Timothy Huff is the second largest time occured Agent name."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows Agent Wendy Taylor as the most frequently occurring agent, with Agent Timothy Huff in second place. These insights suggest leveraging Wendy’s expertise could enhance team performance and client satisfaction. However, heavy reliance on Wendy might lead to burnout, and Timothy’s lower ranking could indicate performance issues. Addressing these concerns with balanced workloads and targeted training can prevent negative impacts and foster positive growth."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# Pair Plot visualization code\n",
        "sns.pairplot(df_cleaned[['response_time', 'csat_score', 'item_price']], diag_kind='kde')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A pair plot (scatterplot matrix) is useful for visualizing relationships between multiple numerical variables. It helps identify trends, correlations, and outliers in customer support data across response time, CSAT score, and item price."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* CSAT score is mostly discrete, clustering around 1 to 5, indicating a rating-based system.\n",
        "* Response time is highly skewed, with a concentration of values near 0-50 but some extreme negative values, suggesting possible data entry errors or preprocessing issues.\n",
        "* Higher-priced items have more varied response times, but lower-priced items dominate the dataset, indicating that most customer queries are related to affordable products.\n",
        "* No strong visible correlation between item price and CSAT score, meaning expensive items don't necessarily lead to better or worse satisfaction.\n",
        "* Some outliers exist in item price and response time, which might need further investigation.\n",
        "* Negative response times might indicate incorrect timestamps or agent workflow inefficiencies.\n",
        "* Uneven distribution of CSAT scores suggests that certain factors (other than price or response time) significantly impact satisfaction."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the distribution of CSAT scores, I found that the mean CSAT score is 4.22. Let's use hypothesis testing to see if this statement is true.\n",
        "\n",
        "Null Hypothesis (H₀): μ = 4.22\n",
        "\n",
        "Alternate Hypothesis (H₁): μ ≠ 4.22"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# Test data for CSAT Score\n",
        "test_data2 = df_cleaned['csat_score']\n",
        "\n",
        "# Hypothesized mean is 4.24\n",
        "hypothesized_mean = 4.22\n",
        "\n",
        "# Conduct one-sample t-test\n",
        "stats, p = ttest_1samp(test_data2, hypothesized_mean)\n",
        "\n",
        "print('t-statistic = %.2f, p-value = %.3f' % (stats, p))\n",
        "\n",
        "alpha = 0.05\n",
        "if p < alpha:\n",
        "    print(\"Reject null hypothesis: The mean CSAT score is significantly different from 4.22.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The mean CSAT score is not significantly different from 4.22.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have conducted One sample t-test to obtain p-value"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chosen one-sample t-test because I wanted to determine if the mean CSAT score in my dataset is significantly different from 4.22. This test is ideal for comparing the sample mean to a specific value, and it’s suitable for my data to check if it deviates from the hypothesized population mean."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Item_price mean is 1439.22 in the data set, Let us conduct a Hypothesis testing to know the mean value of Item_price is significantly different or not.\n",
        "\n",
        "Null Hypothesis (H₀): μ = 1439.22\n",
        "\n",
        "Alternate Hypothesis (H₁): μ ≠ 1439.22"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_1samp"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_1samp\n",
        "\n",
        "# Define the hypothesized mean\n",
        "hypothesized_mean = 1439.22\n",
        "\n",
        "# Perform one-sample t-test\n",
        "test_data1 = df_cleaned['item_price']\n",
        "t_stat, p_value = ttest_1samp(test_data1, hypothesized_mean)\n",
        "\n",
        "# Print the t-statistic and p-value\n",
        "print('t-statistic = %.2f, p-value = %.3f' % (t_stat, p_value))\n",
        "\n",
        "# Define significance level (commonly 0.05)\n",
        "alpha = 0.05\n",
        "\n",
        "# Make a decision based on p-value\n",
        "if p_value <= alpha:\n",
        "    print(\"Reject null hypothesis: The mean of Item_price is significantly different from 1439.22.\")\n",
        "else:\n",
        "    print(\"Fail to reject null hypothesis: The mean of Item_price is not significantly different from 1439.22.\")"
      ],
      "metadata": {
        "id": "-8Sz0Huz0dwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have conducted one sample t-test to obrain the p-value."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the one-sample t-test because I wanted to know if the mean Itme_price in my dataset is significantly different from 1439.22. This test is ideal for comparing the sample mean to a specific value, and it’s suitable for my data to check if it deviates from the hypothesized population mean."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "print(df_cleaned.isnull().sum())"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset currently contains no null values. However, if null values were to be introduced, we could use suitable imputation methods to fill them in. The choice of imputation technique would depend on the nature and distribution of the data, ensuring that we maintain the dataset's integrity and accuracy."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "# Calculate Q1 and Q3 while excluding zeros\n",
        "Q1 = df_cleaned[df_cleaned['item_price'] != 0]['item_price'].quantile(0.25)\n",
        "Q3 = df_cleaned[df_cleaned['item_price'] != 0]['item_price'].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Determine the lower and upper bounds for outliers, excluding zeros\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Identify outliers without creating a new DataFrame\n",
        "outliers = df_cleaned[(df_cleaned['item_price'] < lower_bound) | (df_cleaned['item_price'] > upper_bound) & (df_cleaned['item_price'] != 0)]\n",
        "\n",
        "# Output the count of outliers\n",
        "print(f\"Number of outliers: {len(outliers)}\")"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate percentage of outliers\n",
        "outlier_percentage = (len(outliers) / len(df_cleaned)) * 100\n",
        "print(f\"Percentage of outliers in Item_price: {outlier_percentage:.2f}%\")"
      ],
      "metadata": {
        "id": "1gfBSdrO2HgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "\n",
        "!pip install category_encoders"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify categorical features with high cardinality (more than 30 unique values)\n",
        "cat_features_high_car = [column for column in df_cleaned.columns if df_cleaned[column].dtype == 'object' and len(df_cleaned[column].unique()) > 30]\n",
        "\n",
        "# Identify categorical features with low cardinality (30 or fewer unique values)\n",
        "cat_features = [column for column in df_cleaned.columns if df_cleaned[column].dtype == 'object' and len(df_cleaned[column].unique()) <= 30]\n",
        "\n",
        "# Import BinaryEncoder for high-cardinality features and necessary transformers from sklearn\n",
        "from category_encoders import BinaryEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Initialize BinaryEncoder for high-cardinality categorical features\n",
        "encoder = BinaryEncoder(cols=cat_features_high_car)\n",
        "\n",
        "# Apply Binary Encoding to the cleaned data\n",
        "df_encoded = encoder.fit_transform(df_cleaned)\n",
        "\n",
        "# Initialize OneHotEncoder for low-cardinality categorical features\n",
        "onehotencoder = OneHotEncoder(drop='first', sparse_output=False, dtype=np.int64)\n",
        "\n",
        "# Create a ColumnTransformer to apply OneHotEncoder to low-cardinality features\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        (\"OneHotEncoder\", onehotencoder, cat_features),  # Apply OneHotEncoder to low-cardinality features\n",
        "    ], remainder='passthrough'  # Pass through other columns without transformation\n",
        ")\n",
        "\n",
        "# Apply One-Hot Encoding to low-cardinality features and pass through high-cardinality features\n",
        "df_encoded = preprocessor.fit_transform(df_encoded)\n",
        "\n",
        "# Convert the transformed array back to a DataFrame with feature names\n",
        "df_encoded = pd.DataFrame(df_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "# Display the first few rows of the encoded DataFrame\n",
        "print(\"Encoded DataFrame head:\")\n",
        "print(df_encoded.head())"
      ],
      "metadata": {
        "id": "g1qgu81M4B5P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mzeMoOeK4COv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xkWUiT8k4zVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OeQlrQoc4CSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used both One-Hot Encoding and Binary Encoding for categorical columns in my dataset.\n",
        "\n",
        "One-Hot Encoding: Applied to categorical columns without an inherent order or ranking, such as channel_name, category, Sub-category,Customer Remarks, Customer_City etc.\n",
        "\n",
        "Binary Encoding: Used for categorical columns with high cardinality, such as Item_price, Agent_name, Supervisor, Manager, Agent Shift. Binary Encoding was chosen to manage the large number of features that One-Hot Encoding would have introduced"
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have droped Unique id column because it lacks significant predictive power."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Channel Name: Different channels may influence customer engagement levels and their likelihood of making a purchase.\n",
        "\n",
        "2.Product Category: Various product categories can attract different customer segments with distinct preferences and interests.\n",
        "\n",
        "3.Customer Remarks: Feedback from customers can provide insights into their satisfaction and concerns, influencing their future purchasing decisions.\n",
        "\n",
        "4.Order ID: While not predictive by itself, it helps in tracking customer transactions and behaviors.\n",
        "\n",
        "5.Order Date Time: The timing of orders may reveal trends related to peak purchasing times or seasonal interests.\n",
        "\n",
        "6.Issue Reported At: The timestamp of reported issues can indicate common pain points and the urgency of customer needs.\n",
        "\n",
        "7.Issue Responded: The response time for issues may affect customer satisfaction and loyalty.\n",
        "\n",
        "8.Survey Response Date: This feature is crucial for understanding the timing of customer feedback and its relation to their experience.\n",
        "\n",
        "9.Customer City: The location of customers can influence their purchasing habits and preferences based on regional factors.\n",
        "\n",
        "10.Item Price: The price of items plays a significant role in customer interest and purchasing decisions.\n",
        "\n",
        "11.Agent Name: Different agents may have varying success rates in closing sales, impacting overall performance.\n",
        "\n",
        "12.Supervisor and Manager: These roles might reflect the support structure behind sales, which could influence customer interactions.\n",
        "\n",
        "13.Tenure Bucket: This indicates how long customers have been with the company, which can correlate with their loyalty and purchasing behavior.\n",
        "\n",
        "14.Agent Shift: The timing of agent shifts might affect customer availability and engagement"
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "num_columns = [column for column in X_train.columns if X_train[column].dtype != \"object\" and len(X_train[column].unique()) > 10]\n",
        "\n",
        "# Import StandardScaler from sklearn\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform the numerical columns\n",
        "X_train[num_columns] = scaler.fit_transform(X_train[num_columns])\n",
        "\n",
        "# Transform the numerical columns of the test data using the fitted scaler\n",
        "X_test[num_columns] = scaler.transform(X_test[num_columns])"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the original feature column names\n",
        "features_columns = X_train.columns\n",
        "\n",
        "# Convert the DataFrame to a NumPy array\n",
        "# X_train = X_train.values\n",
        "\n",
        "# Convert the test set DataFrame to a NumPy array\n",
        "# X_test = X_test.values"
      ],
      "metadata": {
        "id": "RE3j3-wE6YJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7ZN4DXNs6Yt9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Standard Scaling (via StandardScaler) because it normalizes features to have a mean of 0 and a standard deviation of 1. This ensures equal contribution from all features, improves convergence for algorithms, and handles features with different units effectively"
      ],
      "metadata": {
        "id": "yidg_ZfQ6oWu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely."
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set default behavior to not show grid lines for all plots\n",
        "plt.rcParams['axes.grid'] = False  # Disable grid lines globally\n",
        "\n",
        "# Then proceed to create your plots"
      ],
      "metadata": {
        "id": "4Og1iyMR66zD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# << ML Model Building >\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, ConfusionMatrixDisplay, RocCurveDisplay"
      ],
      "metadata": {
        "id": "mbHzjTnX7EKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL 01 : Descision Tree**"
      ],
      "metadata": {
        "id": "XQQvoWWx7Tkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "model_1 = DecisionTreeClassifier()\n",
        "\n",
        "# Fit the Algorithm\n",
        "model_1.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "model_1_pred = model_1.predict(X_test)"
      ],
      "metadata": {
        "id": "HPPCeyXy7EU8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 📦 Import necessary libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Ensure df_cleaned and df_encoded are available from previous steps\n",
        "\n",
        "# 🎯 Define features (X) and target (y)\n",
        "# Explicitly drop original datetime columns from df_cleaned before encoding\n",
        "df_processed = df_cleaned.drop(columns=['issue_reported_at', 'issue_responded', 'order_date_time'], errors='ignore')\n",
        "\n",
        "# Re-perform categorical encoding on df_processed\n",
        "# Identify categorical features with high cardinality (more than 30 unique values)\n",
        "cat_features_high_car = [column for column in df_processed.columns if df_processed[column].dtype == 'object' and len(df_processed[column].unique()) > 30]\n",
        "\n",
        "# Identify categorical features with low cardinality (30 or fewer unique values)\n",
        "cat_features = [column for column in df_processed.columns if df_processed[column].dtype == 'object' and len(df_processed[column].unique()) <= 30]\n",
        "\n",
        "# Import BinaryEncoder for high-cardinality features and necessary transformers from sklearn\n",
        "from category_encoders import BinaryEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "# Initialize BinaryEncoder for high-cardinality categorical features\n",
        "encoder = BinaryEncoder(cols=cat_features_high_car)\n",
        "\n",
        "# Apply Binary Encoding to the processed data\n",
        "df_encoded = encoder.fit_transform(df_processed)\n",
        "\n",
        "# Initialize OneHotEncoder for low-cardinality categorical features\n",
        "onehotencoder = OneHotEncoder(drop='first', sparse_output=False, dtype=np.int64)\n",
        "\n",
        "# Create a ColumnTransformer to apply OneHotEncoder to low-cardinality features\n",
        "preprocessor = ColumnTransformer(\n",
        "    [\n",
        "        (\"OneHotEncoder\", onehotencoder, cat_features),  # Apply OneHotEncoder to low-cardinality features\n",
        "    ], remainder='passthrough'  # Pass through other columns without transformation\n",
        ")\n",
        "\n",
        "# Apply One-Hot Encoding to low-cardinality features and pass through high-cardinality features\n",
        "df_encoded = preprocessor.fit_transform(df_encoded)\n",
        "\n",
        "# Convert the transformed array back to a DataFrame with feature names\n",
        "df_encoded = pd.DataFrame(df_encoded, columns=preprocessor.get_feature_names_out())\n",
        "\n",
        "# Use the encoded DataFrame for features\n",
        "X = df_encoded.copy()\n",
        "\n",
        "# Drop datetime columns that might have been passed through with 'remainder__' prefix\n",
        "datetime_remainder_cols = [col for col in X.columns if col.startswith('remainder__') and ('issue_reported_at' in col or 'issue_responded' in col or 'order_date_time' in col)]\n",
        "X = X.drop(columns=datetime_remainder_cols, errors='ignore')\n",
        "\n",
        "\n",
        "# Create a binary target variable based on CSAT Score from df_cleaned\n",
        "# Assuming a threshold of 4 for binary classification (CSAT Score > 4 is 'High')\n",
        "y = np.where(df_cleaned['csat_score'] > 4, 'High', 'Low')\n",
        "\n",
        "\n",
        "# 🧪 Train-Test Split\n",
        "# Use X and y\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# 🌳 ML Model - 1: Decision Tree Classifier\n",
        "model_1 = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# ✅ Fit the model\n",
        "model_1.fit(X_train, y_train)\n",
        "\n",
        "# 🔍 Predict on test set\n",
        "model_1_pred = model_1.predict(X_test)\n",
        "\n",
        "# 📊 Evaluate the model\n",
        "print(\"✅ Accuracy Score:\", accuracy_score(y_test, model_1_pred))\n",
        "print(\"\\n📉 Confusion Matrix:\\n\", confusion_matrix(y_test, model_1_pred))\n",
        "print(\"\\n📄 Classification Report:\\n\", classification_report(y_test, model_1_pred))"
      ],
      "metadata": {
        "id": "Iyd34GOq8VFE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, model_1_pred))"
      ],
      "metadata": {
        "id": "y8SBQJym80ki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, model_1_pred))"
      ],
      "metadata": {
        "id": "_O6_r1Yt9Dwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the confusion matrix for the Decision Tree model\n",
        "ConfusionMatrixDisplay.from_estimator(model_1, X_test, y_test)\n",
        "\n",
        "# Add a title\n",
        "plt.title('Confusion Matrix for Decision Tree Classifier', fontweight='bold')\n",
        "plt.grid(False)\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DA-94JgB80xj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'High' is the positive class for ROC curve calculation\n",
        "# Get the index of the 'High' class in the model's classes\n",
        "positive_class_index = np.where(model_1.classes_ == 'High')[0][0]\n",
        "\n",
        "# Predict probabilities for the ROC curve using model_1\n",
        "y_score = model_1.predict_proba(X_test)\n",
        "\n",
        "# Calculate the ROC curve for the positive class ('High')\n",
        "# roc_curve expects true binary labels and prediction scores for the positive class\n",
        "# We use y_test directly and the probabilities of the positive class\n",
        "fpr, tpr, _ = roc_curve(y_test, y_score[:, positive_class_index], pos_label='High')\n",
        "\n",
        "# Calculate the AUC\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Initialize a ROC curve plot\n",
        "plt.figure()\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Plot diagonal for random guessing\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Model 1 Before Cross-Validation')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True) # Add grid for better readability\n",
        "\n",
        "# Display the ROC curve plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ws9WkOxXAYbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define the decision tree model\n",
        "model_1 = DecisionTreeClassifier()\n",
        "\n",
        "# Perform cross-validation (cv=3 for 3-fold cross-validation)\n",
        "cv_scores = cross_val_score(model_1, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Output the cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean CV Accuracy:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "id": "-YO5gRVS8VOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d-gTD0gv-DP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ut9EpDFX-DdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z4C521E59_kL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "97CdmFSR9_nt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "pK1qBQuk9_7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "# Create a dictionary for evaluation metrics for model_2\n",
        "evaluation_dict_model_1 = {\n",
        "    'Model Name': 'model_1',\n",
        "    'Model Type': 'Decision Tree Classifier',\n",
        "    'Accuracy': accuracy_score(y_test, model_1_pred),\n",
        "    'Recall': recall_score(y_test, model_1_pred, average='weighted'),\n",
        "    'Precision': precision_score(y_test, model_1_pred, average='weighted'),\n",
        "    'F1-Score': f1_score(y_test, model_1_pred, average='weighted')\n",
        "}\n",
        "\n",
        "# Convert the dictionary into a DataFrame for easy visualization\n",
        "evaluation_df_model_1 = pd.DataFrame(evaluation_dict_model_1, index=[0])\n",
        "\n",
        "# Output the DataFrame\n",
        "evaluation_df_model_1"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define the decision tree model\n",
        "model_1 = DecisionTreeClassifier()\n",
        "\n",
        "# Perform cross-validation (cv=3 for 3-fold cross-validation)\n",
        "cv_scores = cross_val_score(model_1, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Output the cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean CV Accuracy:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Fit the model on the training data to get the class order\n",
        "model_1.fit(X_train, y_train)\n",
        "\n",
        "# Perform cross-validation and predict probabilities on the entire dataset\n",
        "y_score_cv = cross_val_predict(model_1, X, y, cv=3, method='predict_proba', n_jobs=-1)\n",
        "\n",
        "# Assuming the positive class is 'High' and it's at the correct index in y_score_cv\n",
        "# Determine the index of the 'High' class from the fitted model's classes\n",
        "positive_class_index = np.where(model_1.classes_ == 'High')[0][0]\n",
        "y_score_positive_cv = y_score_cv[:, positive_class_index]\n",
        "\n",
        "# Calculate the ROC curve\n",
        "# Use the original y (before train-test split) for cross-validation ROC\n",
        "fpr_cv, tpr_cv, thresholds_cv = roc_curve(y, y_score_positive_cv, pos_label='High')\n",
        "\n",
        "# Calculate the AUC\n",
        "roc_auc_cv = auc(fpr_cv, tpr_cv)\n",
        "\n",
        "# Initialize a ROC curve plot\n",
        "plt.figure()\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.plot(fpr_cv, tpr_cv, color='darkorange', lw=2, label=f'Cross-Validation ROC curve (AUC = {roc_auc_cv:.2f})')\n",
        "\n",
        "# Plot diagonal for random guessing\n",
        "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve for Decision Tree (Model 1 after Cross-Validation)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True) # Add grid for better readability\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QwSQjx9OB69V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    'max_depth': [10, 20, 30, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "# Initialize GridSearchCV with the Decision Tree model, parameter grid, and cross-validation folds\n",
        "grid_search = GridSearchCV(DecisionTreeClassifier(random_state=42), param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV to the training data to find the best parameters\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Output the best parameters and best score found by GridSearchCV\n",
        "print(\"Best parameters: \", grid_search.best_params_)\n",
        "print(\"Best score: \", grid_search.best_score_)\n",
        "\n",
        "# Get the best model from GridSearchCV\n",
        "best_model_1 = grid_search.best_estimator_\n",
        "\n",
        "# Predict using the best model\n",
        "best_model_1_pred = best_model_1.predict(X_test)\n",
        "# Evaluate the best model's performance\n",
        "print(classification_report(y_test, best_model_1_pred))\n",
        "\n",
        "# Create a dictionary for evaluation metrics for the best model\n",
        "evaluation_dict_best_model_1 = {\n",
        "    'Model Name': 'Best Model 1',\n",
        "    'Model Type': 'Tuned Decision Tree Classifier',\n",
        "    'Accuracy': accuracy_score(y_test, best_model_1_pred),\n",
        "    'Recall': recall_score(y_test, best_model_1_pred, average='weighted'),\n",
        "    'Precision': precision_score(y_test, best_model_1_pred, average='weighted'),\n",
        "    'F1-Score': f1_score(y_test, best_model_1_pred, average='weighted')\n",
        "}\n",
        "\n",
        "# Convert the dictionary into a DataFrame\n",
        "evaluation_df_best_model_1 = pd.DataFrame(evaluation_dict_best_model_1, index=[0])\n",
        "\n",
        "# Output the DataFrame\n",
        "evaluation_df_best_model_1\n",
        "\n",
        "# Plot the confusion matrix for the best model\n",
        "ConfusionMatrixDisplay.from_estimator(best_model_1, X_test, y_test)\n",
        "\n",
        "# Add a title\n",
        "plt.title('Confusion Matrix for Tuned Decision Tree Classifier', fontweight='bold')\n",
        "plt.grid(False)\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OxwzlDK6B7G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Visualizing evaluation Metric Score chart\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "# Create a dictionary for evaluation metrics for DT\n",
        "evaluation_dt_cv = {\n",
        "    'Model Name': 'Model-1(Tune)',\n",
        "    'Model Type': 'Decision Tree Classifier',\n",
        "    'Accuracy': accuracy_score(y_test, best_model_1_pred),\n",
        "    'Recall': recall_score(y_test, best_model_1_pred, average='weighted'),\n",
        "    'Precision': precision_score(y_test, best_model_1_pred, average='weighted'),\n",
        "    'F1-Score': f1_score(y_test, best_model_1_pred, average='weighted')\n",
        "}\n",
        "\n",
        "# Convert the dictionary into a DataFrame for easy visualization\n",
        "evaluation_customer_support_records_dt_cv = pd.DataFrame(evaluation_dt_cv, index=[0])\n",
        "\n",
        "# Output the DataFrame\n",
        "print(\"Update Evaluation metric Score Chart\")\n",
        "evaluation_customer_support_records_dt_cv"
      ],
      "metadata": {
        "id": "GXXOoZUKB7Sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used GridSearchCV, which stands for Grid Search with Cross Validation. Because it tests all possible combinations of the hyperparameters you specify and finds the one that gives the best model performance (based on accuracy in this case). It's a reliable method for improving model performance by tuning parameters like max_depth, criterion, and min_samples_split."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, My chart clearly shows improvement in all evaluation metrics after tuning your model. Here's a simple breakdown of the improvements.After tuning your model, all metrics went up, even if just a little.The F1-Score saw the most improvement, which means your model is now better at balancing precision and recall.These small improvements suggest that tuning made your model more accurate and reliable overall."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2 ( Random Forest )"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 2 Implementation\n",
        "model_2 = RandomForestClassifier()\n",
        "# Fit the Algorithm\n",
        "model_2.fit(X_train, y_train)\n",
        "# Predict on the model\n",
        "model_2_pred = model_2.predict(X_test)\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, model_2_pred))"
      ],
      "metadata": {
        "id": "y5Rb1uZkGph3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "# Create a dictionary for evaluation metrics\n",
        "evaluation_dict = {\n",
        "    'Model Name': 'model_2',\n",
        "    'Model Type': 'Random Forest Classifier',\n",
        "    'Accuracy': accuracy_score(y_test, model_2_pred),\n",
        "    'Recall': recall_score(y_test, model_2_pred, average='weighted'),  # Use 'weighted' for multiclass\n",
        "    'Precision': precision_score(y_test, model_2_pred, average='weighted'),  # Use 'weighted' for multiclass\n",
        "    'F1-Score': f1_score(y_test, model_2_pred, average='weighted')  # Use 'weighted' for multiclass\n",
        "}\n",
        "\n",
        "# Convert the dictionary into a DataFrame\n",
        "evaluation_df = pd.DataFrame(evaluation_dict, index=[0])\n",
        "\n",
        "# Output the DataFrame\n",
        "evaluation_df"
      ],
      "metadata": {
        "id": "fI909FoxGprd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display confusion matrix\n",
        "ConfusionMatrixDisplay.from_estimator(model_2, X_test, y_test)\n",
        "plt.title('Confusion Matrix (Random Forest)', fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q28kWCFsHibD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'High' is the positive class for ROC curve calculation\n",
        "# Get the index of the 'High' class in the model's classes\n",
        "# Ensure model_2 is fitted before accessing classes_\n",
        "if 'model_2' in locals() and hasattr(model_2, 'classes_'):\n",
        "    positive_class_index = np.where(model_2.classes_ == 'High')[0][0]\n",
        "\n",
        "    # Predict probabilities for the ROC curve\n",
        "    y_score = model_2.predict_proba(X_test)\n",
        "\n",
        "    # Calculate the ROC curve for the positive class ('High')\n",
        "    # roc_curve expects true binary labels and prediction scores for the positive class\n",
        "    # We use y_test directly and the probabilities of the positive class\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_score[:, positive_class_index], pos_label='High')\n",
        "\n",
        "    # Calculate the AUC\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    # Initialize a ROC curve plot\n",
        "    plt.figure()\n",
        "\n",
        "    # Plot the ROC curve\n",
        "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "\n",
        "    # Plot diagonal for random guessing\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "    # Add labels and title\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve for Model 2 (Random Forest) Before Cross-Validation')\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True) # Add grid for better readability\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Model 'model_2' is not defined or not fitted. Please train Model 2 before plotting the ROC curve.\")"
      ],
      "metadata": {
        "id": "8kNHnpDFHyC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a random forest classifier\n",
        "model_2 = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model_2.fit(X_train, y_train)\n",
        "\n",
        "# Binarize the output labels for multi-class ROC curve calculation\n",
        "n_classes = len(np.unique(y_test))\n",
        "y_test_binarized = label_binarize(y_test, classes=np.arange(n_classes))\n",
        "\n",
        "# Predict probabilities for the ROC curve\n",
        "y_score = model_2.predict_proba(X_test)\n",
        "\n",
        "# Initialize a ROC curve plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# For each class, compute the ROC curve\n",
        "for i in range(n_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_score[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'Class {iris.target_names[i]} ROC (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Plot diagonal for random guessing\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Model 2 (Random Forest)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Display the ROC curve plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "q5_17Tv_HyMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eVRZeHZ1HioA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform cross-validation (cv=3 for 3-fold cross-validation)\n",
        "cv_scores = cross_val_score(model_2, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Output the cross-validation scores\n",
        "print(\"Cross-Validation Scores:\", cv_scores)\n",
        "print(\"Mean CV Accuracy:\", cv_scores.mean())"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I utilized K-Fold Cross-Validation for optimizing the Random Forest model. This technique was selected because it effectively balances model evaluation and computational efficiency.\n",
        "\n",
        "The scores obtained from cross-validation ([0.7938, 0.8329, 0.9756]) reflect the model's performance across different subsets, indicating a robust evaluation. The mean CV accuracy of approximately 0.87 demonstrates the model’s overall effectiveness and its ability to generalize well to unseen data. K-Fold Cross-Validation provides a comprehensive assessment of model stability and performance, making it a reliable choice for this analysis"
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model again on the cross-validated dataset (if necessary)\n",
        "model_2.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities for the ROC curve\n",
        "y_score_cv = model_2.predict_proba(X_test)\n",
        "\n",
        "# Initialize a ROC curve plot\n",
        "plt.figure()\n",
        "\n",
        "# For each class, compute the ROC curve\n",
        "for i in range(n_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_score_cv[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'Class {i + 1} ROC (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Plot diagonal for random guessing\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Model 3 (Random Forest) After Cross-Validation')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Display the ROC curve plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7wwm3oQUJpEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Enhancements Following Cross-Validation:**\n",
        "After conducting cross-validation, the AUC remained stable, indicating that the model's ability to distinguish between classes did not change. This consistency suggests that the model is reliable and robust, as it maintained its performance level across different subsets of the data. The unchanged AUC also implies that the cross-validation process effectively validated the model without introducing any significant variations in its predictive capability."
      ],
      "metadata": {
        "id": "xa8jfFTqJ7Uh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BUXDXdJdFnLp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3 ( Extra Trees )"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Initialize Extra Trees Classifier\n",
        "model_3 = ExtraTreesClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "model_3.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_et = model_3.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred_et))"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "# Create a dictionary for evaluation metrics\n",
        "evaluation_dict_et = {\n",
        "    'Model Name': 'Model_3',\n",
        "    'Model Type': 'Extra Trees Classifier',\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_et),\n",
        "    'Recall': recall_score(y_test, y_pred_et, average='weighted'),  # Use 'weighted' for multiclass\n",
        "    'Precision': precision_score(y_test, y_pred_et, average='weighted'),  # Use 'weighted' for multiclass\n",
        "    'F1-Score': f1_score(y_test, y_pred_et, average='weighted')  # Use 'weighted' for multiclass\n",
        "}\n",
        "\n",
        "# Convert the dictionary into a DataFrame\n",
        "evaluation_df_et = pd.DataFrame(evaluation_dict_et, index=[0])\n",
        "\n",
        "# Output the DataFrame\n",
        "evaluation_df_et"
      ],
      "metadata": {
        "id": "lKk3htUCKue7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gUHPwysyK8b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualizing Confusion Matrix for Extra Trees Classifier\n",
        "ConfusionMatrixDisplay.from_estimator(model_3, X_test, y_test)\n",
        "plt.title('Confusion Matrix - Extra Trees Classifier', fontweight='bold')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WNsOazUaK9jY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "\n",
        "# Binarize the output labels for multi-class ROC curve calculation\n",
        "n_classes = len(np.unique(y_test))  # Adjust according to your dataset\n",
        "y_test_binarized = label_binarize(y_test, classes=np.arange(1, n_classes + 1))\n",
        "\n",
        "# Predict probabilities for the ROC curve\n",
        "y_score_et = model_3.predict_proba(X_test)\n",
        "\n",
        "# Initialize a ROC curve plot\n",
        "plt.figure()\n",
        "\n",
        "# For each class, compute the ROC curve\n",
        "for i in range(n_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_score_et[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'Class {i + 1} ROC (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Plot diagonal for random guessing\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Extra Trees Classifier - Before Cross-Validation')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Display the ROC curve plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T7GTR7YKLJrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GFunzo0eLKAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jQW_VHxXLKOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Perform cross-validation (cv=3 for 3-fold cross-validation)\n",
        "cv_scores_et = cross_val_score(model_3, X_train, y_train, cv=3, scoring='accuracy', n_jobs=-1)\n",
        "\n",
        "# Output the cross-validation scores\n",
        "print(\"Cross-Validation Scores (Extra Trees):\", cv_scores_et)\n",
        "print(\"Mean CV Accuracy (Extra Trees):\", cv_scores_et.mean())"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I utilized K-Fold Cross-Validation for optimizing the Extra Trees model. By partitioning the dataset into three folds, each fold serves as a test set once, while the remaining two folds are employed for training. The cross-validation scores obtained from the Extra Trees model were [0.7938, 0.8329, 0.9756], reflecting its performance across various subsets. The mean CV accuracy of approximately 0.8674 indicates the model's effectiveness and its capability to generalize well to unseen data.\n",
        "\n"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Refit the model if cross-validation gave you new hyperparameters (if tuning)\n",
        "# Otherwise, continue using the previously fitted model\n",
        "\n",
        "# Predict probabilities for the ROC curve after cross-validation\n",
        "y_score_et_cv = model_3.predict_proba(X_test)\n",
        "\n",
        "# Initialize a ROC curve plot\n",
        "plt.figure()\n",
        "\n",
        "# For each class, compute the ROC curve after cross-validation\n",
        "for i in range(n_classes):\n",
        "    fpr, tpr, _ = roc_curve(y_test_binarized[:, i], y_score_et_cv[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    plt.plot(fpr, tpr, label=f'Class {i + 1} ROC (AUC = {roc_auc:.2f})')\n",
        "\n",
        "# Plot diagonal for random guessing\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve for Extra Trees Classifier - After Cross-Validation')\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "# Display the ROC curve plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "b3Di0ESjLuD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yhyFmQkELuYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Precision: Ensures that the model accurately targets the right customers, minimizing the risk of false positives and reducing unnecessary marketing efforts.\n",
        "\n",
        "Recall: Prioritizes identifying as many interested customers as possible, ensuring no potential customers are overlooked.\n",
        "\n",
        "F1 Score: Provides a balanced measure by combining precision and recall, offering a clearer view of the model’s overall performance.\n",
        "\n",
        "ROC-AUC: Evaluates the model’s ability to differentiate between interested and non-interested customers across various thresholds, giving insight into its classification effectiveness.\n",
        "\n",
        "Confusion Matrix: Highlights specific prediction errors, helping to pinpoint areas for improvement in the model's decision-making process\n",
        "\n"
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ohn8AtFcMg9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YzWXz526MhFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2QIIDPlfMhLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure X_train is a DataFrame or use X.columns if X_train is a NumPy array\n",
        "# If X_train is a NumPy array, you need to get the column names from the original DataFrame X\n",
        "# If X is also a NumPy array (after transformations), you might need to get column names from df_encoded\n",
        "# Assuming X_train is a DataFrame after the split, or X (before split) is a DataFrame:\n",
        "\n",
        "try:\n",
        "    # Try to get columns from X_train if it's a DataFrame\n",
        "    feature_names = X_train.columns\n",
        "except AttributeError:\n",
        "    # If X_train is a NumPy array, try to get columns from X (assuming X is a DataFrame)\n",
        "    try:\n",
        "        feature_names = X.columns\n",
        "    except AttributeError:\n",
        "        # If both are NumPy arrays, try to get column names from df_encoded\n",
        "        try:\n",
        "            feature_names = df_encoded.columns\n",
        "        except AttributeError:\n",
        "            print(\"Could not get feature names from X_train, X, or df_encoded.\")\n",
        "            feature_names = [] # Fallback to an empty list or handle as appropriate\n",
        "\n",
        "\n",
        "# Ensure model_3 is defined and fitted on the customer support data before running this cell\n",
        "# Example: model_3.fit(X_train, y_train)\n",
        "\n",
        "# Check if model_3 is fitted and has feature_importances_\n",
        "if 'model_3' in locals() and hasattr(model_3, 'feature_importances_'):\n",
        "    if len(feature_names) == len(model_3.feature_importances_):\n",
        "        feature_df = pd.DataFrame({'feature_name': feature_names, 'feature_importance': model_3.feature_importances_})\n",
        "        # You can now display or further process feature_df\n",
        "        print(feature_df.sort_values('feature_importance', ascending=False).head()) # Example: print top features\n",
        "    else:\n",
        "        print(f\"Mismatch between number of feature names ({len(feature_names)}) and feature importances ({len(model_3.feature_importances_)}).\")\n",
        "        print(\"Please ensure the correct features were used for training model_3.\")\n",
        "else:\n",
        "    print(\"Model 'model_3' is not defined or not fitted with feature_importances_.\")\n",
        "    print(\"Please ensure you have trained Model 3 (Extra Trees) on the customer support data before running this cell.\")"
      ],
      "metadata": {
        "id": "qxnajRL4R2Cn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# Train a random forest classifier\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get feature importance values\n",
        "feature_importance = model.feature_importances_\n",
        "\n",
        "# Create a DataFrame with feature names and importance values\n",
        "feature_df = pd.DataFrame({'feature': feature_names, 'feature_importance': feature_importance})\n",
        "\n",
        "# Sort the DataFrame by feature importance\n",
        "feature_df.sort_values(by='feature_importance', ascending=False, inplace=True)\n",
        "\n",
        "# Print the sorted DataFrame\n",
        "print(feature_df)"
      ],
      "metadata": {
        "id": "IJJ8ZfDsSFXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure model_3 is defined and fitted on the customer support data before running this cell\n",
        "# Example: model_3.fit(X_train, y_train)\n",
        "\n",
        "# Check if model_3 is defined and has feature_importances_\n",
        "if 'model_3' in locals() and hasattr(model_3, 'feature_importances_'):\n",
        "    # Get feature names from the DataFrame before potential conversion to NumPy\n",
        "    # Assuming X_train was derived from X, and X has the correct column names\n",
        "    try:\n",
        "        feature_names = X.columns\n",
        "    except AttributeError:\n",
        "        # Fallback to df_encoded columns if X is not a DataFrame\n",
        "        try:\n",
        "            feature_names = df_encoded.columns\n",
        "        except AttributeError:\n",
        "            print(\"Could not get feature names from X or df_encoded.\")\n",
        "            feature_names = [] # Fallback\n",
        "\n",
        "\n",
        "    if len(feature_names) > 0 and len(feature_names) == len(model_3.feature_importances_):\n",
        "        # Creating feature importance DataFrame\n",
        "        feature_df = pd.DataFrame({\n",
        "            'feature_name': feature_names,\n",
        "            'feature_importance': model_3.feature_importances_\n",
        "        })\n",
        "\n",
        "        # Sort the DataFrame by feature importance\n",
        "        feature_df = feature_df.sort_values(by='feature_importance', ascending=False)\n",
        "\n",
        "        # Adjust the figure size dynamically based on the number of features\n",
        "        num_features = len(feature_df)\n",
        "        plt.figure(figsize=(15, max(6, num_features * 0.2))) # Adjust height based on num features\n",
        "\n",
        "        # Create the horizontal bar plot\n",
        "        sns.barplot(x='feature_importance', y='feature_name', data=feature_df, color='skyblue')\n",
        "\n",
        "        # Labeling and title\n",
        "        plt.xlabel('Feature Importance', fontsize=14)\n",
        "        plt.ylabel('Feature Name', fontsize=12) # Added ylabel for clarity\n",
        "        plt.title('Feature Importance from Extra Trees Model', fontsize=16)\n",
        "        # plt.gca().invert_yaxis()  # Most important feature on top - default for barplot\n",
        "\n",
        "        # Adjust margins to reduce the whitespace on the left\n",
        "        plt.subplots_adjust(left=0.3)  # Increase left margin to reduce whitespace\n",
        "\n",
        "        # Improving the layout\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Display the plot\n",
        "        plt.show()\n",
        "    elif len(feature_names) > 0:\n",
        "         print(f\"Mismatch between number of feature names ({len(feature_names)}) and feature importances ({len(model_3.feature_importances_)}).\")\n",
        "         print(\"Please ensure the correct features were used for training model_3.\")\n",
        "    else:\n",
        "        print(\"Feature names could not be determined.\")\n",
        "\n",
        "else:\n",
        "    print(\"Model 'model_3' is not defined or not fitted with feature_importances_.\")\n",
        "    print(\"Please ensure you have trained Model 3 (Extra Trees) on the customer support data before running this cell.\")"
      ],
      "metadata": {
        "id": "F91GcdDoSFgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns # Import seaborn for better plotting\n",
        "\n",
        "# Assuming you have the following variables:\n",
        "# X_train: training data with feature names as columns (preferably a DataFrame)\n",
        "# model_3: an Extra Trees model with feature_importances_ attribute\n",
        "\n",
        "# Check if model_3 is defined and has feature_importances_\n",
        "if 'model_3' in locals() and hasattr(model_3, 'feature_importances_'):\n",
        "    # Get feature names from the DataFrame before potential conversion to NumPy\n",
        "    # Assuming X_train was derived from X, and X has the correct column names\n",
        "    try:\n",
        "        feature_names = X.columns\n",
        "    except AttributeError:\n",
        "        # Fallback to df_encoded columns if X is not a DataFrame\n",
        "        try:\n",
        "            feature_names = df_encoded.columns\n",
        "        except AttributeError:\n",
        "            print(\"Could not get feature names from X or df_encoded.\")\n",
        "            feature_names = [] # Fallback\n",
        "\n",
        "\n",
        "    if len(feature_names) > 0 and len(feature_names) == len(model_3.feature_importances_):\n",
        "        # Creating feature importance DataFrame\n",
        "        feature_df = pd.DataFrame({\n",
        "            'feature_name': feature_names,\n",
        "            'feature_importance': model_3.feature_importances_\n",
        "        })\n",
        "\n",
        "        # Sort the DataFrame by feature importance\n",
        "        feature_df = feature_df.sort_values(by='feature_importance', ascending=False)\n",
        "\n",
        "        # Adjust the figure size dynamically based on the number of features\n",
        "        num_features = len(feature_df)\n",
        "        plt.figure(figsize=(15, max(6, num_features * 0.2))) # Adjust height based on num features\n",
        "\n",
        "        # Create the horizontal bar plot using seaborn for better aesthetics\n",
        "        sns.barplot(x='feature_importance', y='feature_name', data=feature_df, color='skyblue')\n",
        "\n",
        "        # Labeling and title\n",
        "        plt.xlabel('Feature Importance', fontsize=14)\n",
        "        plt.ylabel('Feature Name', fontsize=12) # Added ylabel for clarity\n",
        "        plt.title('Feature Importance from Extra Trees Model', fontsize=16)\n",
        "        # plt.gca().invert_yaxis()  # Most important feature on top - default for barplot\n",
        "\n",
        "        # Adjust margins to reduce the whitespace on the left\n",
        "        plt.subplots_adjust(left=0.3)  # Increase left margin to reduce whitespace\n",
        "\n",
        "        # Improving the layout\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Display the plot\n",
        "        plt.show()\n",
        "    elif len(feature_names) > 0:\n",
        "         print(f\"Mismatch between number of feature names ({len(feature_names)}) and feature importances ({len(model_3.feature_importances_)}).\")\n",
        "         print(\"Please ensure the correct features were used for training model_3.\")\n",
        "    else:\n",
        "        print(\"Feature names could not be determined.\")\n",
        "\n",
        "else:\n",
        "    print(\"Model 'model_3' is not defined or not fitted with feature_importances_.\")\n",
        "    print(\"Please ensure you have trained Model 3 (Extra Trees) on the customer support data before running this cell.\")"
      ],
      "metadata": {
        "id": "69wm_YhcTGz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Kd0YfWkSFnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this classification project, I have successfully implemented various machine learning models to predict customer satisfaction (CSAT) scores. After evaluating multiple algorithms, I have selected the Extra Trees model as the final choice due to its exceptional performance metrics, including high accuracy, recall, precision, and F1-score.\n",
        "\n",
        "The analysis included assessing feature importance, revealing insights into which features significantly influence CSAT predictions. The project demonstrated the effectiveness of model selection and feature analysis in enhancing predictive capabilities. Overall, this classification project not only provided valuable predictions for customer satisfaction but also highlighted the importance of careful model evaluation and feature engineering in achieving robust outcomes."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2521c6f0"
      },
      "source": [
        "# Load Dataset again to ensure df is defined\n",
        "import pandas as pd\n",
        "try:\n",
        "    df = pd.read_csv(\"/Customer_support_data.csv\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: '/Customer_support_data.csv' not found. Please ensure the file is in the correct directory.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while loading the dataset: {e}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32e7a849"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "# Assuming 'csat_score' is the target variable\n",
        "X = df_encoded.drop('remainder__csat_score', axis=1)  # Features are all columns except CSAT score\n",
        "y = df_encoded['remainder__csat_score']  # Target is CSAT score\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Data splitting complete.\")\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}